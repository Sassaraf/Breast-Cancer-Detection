{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class that loads images without resizing\n",
    "class CustomImageFolder(ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        img = self.transform(img)\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "        self.final_act = nn.Softmax(dim=1)\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv0 = nn.Conv2d(1, 32, 3, stride=1, padding=1)\n",
    "        self.conv1 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n",
    "\n",
    "        self.adaptive = nn.AdaptiveAvgPool2d((4, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear0 = nn.Linear(1024, 256)\n",
    "        self.linear1 = nn.Linear(256, 64)\n",
    "        self.linear2 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv0(x)\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.adaptive(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.linear0(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.final_act(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transforms to be applied to the data\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Load the dataset using CustomImageFolder\n",
    "dataset = CustomImageFolder(root=\"dataset/train_dataset\", transform=transform)\n",
    "\n",
    "# Create a data loader that loads data in batches\n",
    "batch_size = 8\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def count_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    return sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an instance of the CNN and define the loss function and optimizer\n",
    "model = ConvNet()\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Training on device: {device}\")\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"models/cnn_v1_20epochs.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001, betas=(0.9, 0.999))\n",
    "threshold = 0.5\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    loss_val = 0.0\n",
    "    y_true = np.array([], dtype=np.bool_)\n",
    "    y_pred = np.array([], dtype=np.bool_)\n",
    "    print(f\"Epoch [{epoch + 1} / {num_epochs}]\")\n",
    "    for i, data in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = F.one_hot(labels, 2).float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(inputs)\n",
    "        loss = loss_fn(out, labels)\n",
    "        loss.backward()\n",
    "        loss_item = loss.item()\n",
    "        loss_val += loss_item\n",
    "\n",
    "        y_true = np.append(y_true, labels.cpu().numpy()[:,1].astype(np.bool_))\n",
    "        y_pred = np.append(y_pred, (out.cpu().detach() > threshold).numpy()[:,1])\n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(f\"Step: {i + 1}, Loss: {loss_val / (i + 1):.4f}\")\n",
    "            print(classification_report(y_true, y_pred, zero_division=0))\n",
    "            \n",
    "        optimizer.step()\n",
    "    print(f\"Loss: {loss_val / len(dataloader):.4f}\")\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model\n",
    "torch.save(model.state_dict(), \"models/cnn_v1_40epochs.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
