{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckelid/miniconda3/envs/final_project/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class that loads images without resizing\n",
    "class CustomImageFolder(ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        img = self.transform(img)\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "        self.final_act = nn.Softmax(dim=1)\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv0 = nn.Conv2d(1, 32, 3, stride=1, padding=1)\n",
    "        self.conv1 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n",
    "\n",
    "        self.adaptive = nn.AdaptiveAvgPool2d((4, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear0 = nn.Linear(1024, 256)\n",
    "        self.linear1 = nn.Linear(256, 64)\n",
    "        self.linear2 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv0(x)\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.adaptive(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.linear0(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.final_act(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transforms to be applied to the data\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Load the dataset using CustomImageFolder\n",
    "dataset = CustomImageFolder(root=\"dataset/test_dataset\", transform=transform)\n",
    "\n",
    "# Create a data loader that loads data in batches\n",
    "batch_size = 8\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the CNN and define the loss function and optimizer\n",
    "model = ConvNet()\n",
    "\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "print(f\"Training on device: {device}\")\n",
    "model.load_state_dict(torch.load(\"models/cnn_v1_20epochs.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:41<00:00,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.60      0.71      1158\n",
      "        True       0.21      0.54      0.31       232\n",
      "\n",
      "    accuracy                           0.59      1390\n",
      "   macro avg       0.54      0.57      0.51      1390\n",
      "weighted avg       0.76      0.59      0.64      1390\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "y_true = np.array([], dtype=np.bool_)\n",
    "y_pred = np.array([], dtype=np.bool_)\n",
    "with torch.no_grad():\n",
    "    for i, data in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = F.one_hot(labels, 2).float().to(device)\n",
    "        out = model(inputs)\n",
    "        y_true = np.append(y_true, labels.cpu().numpy()[:,1].astype(np.bool_))\n",
    "        y_pred = np.append(y_pred, (out.cpu().detach() > threshold).numpy()[:,1])\n",
    "print(classification_report(y_true, y_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
